{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import libs\nimport os\nimport glob, pylab, pandas as pd\nimport pydicom, numpy as np\nimport random\nimport json\nimport time\nimport copy\nimport pydicom\nimport torchvision\nimport sys\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.autograd import Variable\nfrom PIL import Image, ImageDraw, ImageFont\nimport matplotlib.pyplot as plt\nfrom matplotlib import patches, patheffects\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom torchvision import datasets, transforms\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import lr_scheduler\nfrom pathlib import Path\n\nimport torch.nn.functional as F\n\n# from fastai.conv_learner import *\n# from fastai.dataset import *\n# from fastai.dataset import ImageClassifierData","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pytorch_pretrained_vit","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pytorch_pretrained_vit import ViT\nmodel = ViT('B_16_imagenet1k', pretrained=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\nfrom PIL import Image\nimport torch\nfrom torchvision import transforms\n\n# Load ViT\nfrom pytorch_pretrained_vit import ViT\nmodel = ViT('B_16_imagenet1k', pretrained=True)\nmodel.eval()\n\n# Load image\n# NOTE: Assumes an image `img.jpg` exists in the current directory\nimg = transforms.Compose([\n    transforms.Resize((384, 384)), \n    transforms.ToTensor(),\n    transforms.Normalize(0.5, 0.5),\n])(Image.open('img.jpg')).unsqueeze(0)\nprint(img.shape) # torch.Size([1, 3, 384, 384])\n\n# Classify\nwith torch.no_grad():\n    outputs = model(img)\nprint(outputs.shape)  # (1, 1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/rsna-pneumonia-detection-challenge","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/rsna-pneumonia-detection-challenge/stage_2_train_images | head","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH = '../input/rsna-pneumonia-detection-challenge/'\ndf = pd.read_csv(PATH + 'stage_2_train_labels.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(df.drop_duplicates('patientId').shape)\n# len(list((PATH + 'stage_2_train_images').iterdir()))\nprint(len(os.listdir(PATH + 'stage_2_train_images')))\ndf = df.drop_duplicates('patientId').reset_index(drop=True)\nprint(df.shape)\nprint(df.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"target label to one hot vector"},{"metadata":{"trusted":true},"cell_type":"code","source":"# encoder = LabelEncoder()\n# encoder.fit(df['Target'])\n# df['label'] = encoder.transform(df['Target'])\n# print(df.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"앙상블을 함으로써 performance를 높일 수 있다.\n그러나 train 시간이 더 길어진다.\ntrain data를 3개로 나누고 training후 majority vote로 하자."},{"metadata":{"trusted":true},"cell_type":"code","source":"# df = df[0:2000]\ntrain_df, test_df = train_test_split(df, test_size=0.1)\ntrain2_df, train3_df = train_test_split(train_df, test_size=1/3)\ntrain1_df, train2_df = train_test_split(train2_df, test_size=0.5)\n\ntrain_df.reset_index(drop=True, inplace=True)\ntest_df.reset_index(drop=True, inplace=True)\ntrain1_df.reset_index(drop=True, inplace=True)\ntrain2_df.reset_index(drop=True, inplace=True)\ntrain3_df.reset_index(drop=True, inplace=True)\nprint(train_df.shape)\nprint(len(train_df), len(train1_df), len(train2_df), len(train3_df))\n# train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"data중에서 label 1과 0의 비율은 약 1:4 로 0이 많다.\ntrain/test, 및 train을 각각 3개로 나눌 때도 이 비율이 유지됨을 볼 수 있다.\n\ndataset을 만들때 비율을 고려하여 sampling을 하는 방안을 생각할 수 있다.\n또는 loss를 focal loss로 쓰면서 label 0에 대한 학습시 가중치 update를 낮추는 법도 가능하다."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(df[df['Target']==1])/len(df))\nprint(len(train_df[train_df['Target']==1])/len(train_df))\nprint(len(test_df[test_df['Target']==1])/len(test_df))\nprint(len(train1_df[train1_df['Target']==1])/len(train1_df))\nprint(len(train2_df[train2_df['Target']==1])/len(train2_df))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.transform = transforms.Compose(transform) if transform else None\n        self.dir = PATH + 'stage_2_train_images/'\n\n    def __len__(self):\n        return len(self.df)\n    \n    def read_dicom_image(self, loc):\n        # return numpy array\n        img_arr = pydicom.read_file(loc).pixel_array\n        img_arr = img_arr/img_arr.max()\n        img_arr = (255*img_arr).clip(0, 255).astype(np.uint8)\n        img_arr = Image.fromarray(img_arr).convert('RGB') # model expects 3 channel image\n        return img_arr    \n\n    def __getitem__(self, idx):\n        pid = self.df.iloc[idx, 0]\n#         print(pid)\n        pimage = self.read_dicom_image(self.dir + pid + '.dcm')\n        if self.transform:\n            pimage = self.transform(pimage)\n        label = self.df.iloc[idx, 5]\n        return pid, pimage, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 32\ntransform = [transforms.Resize(224), transforms.RandomHorizontalFlip() , transforms.ToTensor()]\n\ntrain_dataset = MDataset(train_df, transform=transform)\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n\ntest_dataset = MDataset(test_df, transform=transform)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n\ntrain1_dataset = MDataset(train1_df, transform=transform)\ntrain1_loader = DataLoader(train1_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n\ntrain2_dataset = MDataset(train2_df, transform=transform)\ntrain2_loader = DataLoader(train2_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n\ntrain3_dataset = MDataset(train3_df, transform=transform)\ntrain3_loader = DataLoader(train3_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# imbalanced dataset sampler\n1:1 ratio per class\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # # imbalanced dataset sampler\n# # !ls imbalanced-dataset-sampler\n# # !rm -rf imbalanced-dataset-sampler\n# # !git clone https://github.com/ufoym/imbalanced-dataset-sampler\n# # !pip install imbalanced-dataset-sampler/\n\n# import torch\n# import torch.utils.data\n# import torchvision\n\n\nclass ImbalancedDatasetSampler(torch.utils.data.sampler.Sampler):\n    \"\"\"Samples elements randomly from a given list of indices for imbalanced dataset\n    Arguments:\n        indices (list, optional): a list of indices\n        num_samples (int, optional): number of samples to draw\n        callback_get_label func: a callback-like function which takes two arguments - dataset and index\n    \"\"\"\n\n    def __init__(self, dataset, indices=None, num_samples=None, callback_get_label=None):\n                \n        # if indices is not provided, \n        # all elements in the dataset will be considered\n        self.indices = list(range(len(dataset))) \\\n            if indices is None else indices\n\n        # define custom callback\n        self.callback_get_label = callback_get_label\n\n        # if num_samples is not provided, \n        # draw `len(indices)` samples in each iteration\n        self.num_samples = len(self.indices) \\\n            if num_samples is None else num_samples\n            \n        # distribution of classes in the dataset \n        label_to_count = {}\n        for idx in self.indices:\n            label = self._get_label(dataset, idx)\n            if label in label_to_count:\n                label_to_count[label] += 1\n            else:\n                label_to_count[label] = 1\n                \n        # weight for each sample\n        weights = [1.0 / label_to_count[self._get_label(dataset, idx)]\n                   for idx in self.indices]\n        self.weights = torch.DoubleTensor(weights)\n\n    def _get_label(self, dataset, idx):\n#         return dataset.train_labels[idx].item()\n        return dataset.df.loc[idx].Target\n                \n    def __iter__(self):\n        return (self.indices[i] for i in torch.multinomial(\n            self.weights, self.num_samples, replacement=True))\n\n    def __len__(self):\n        return self.num_samples\n\n# from torchsampler import ImbalancedDatasetSampler\n\nimbalanced_train_loader = DataLoader(\n    train_dataset, \n    sampler=ImbalancedDatasetSampler(train_dataset),\n    batch_size=32, \n    shuffle=False, \n#     num_workers=2\n)\n\n# import sys\n# for _, pid, label in imbalanced_train_loader:\n# #     print(pid, label)\n#     print(label)\n#     sys.exit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/65938\n# focal loss for unbalancing label\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha=1, gamma=2, reduce=True):\n        super(FocalLoss, self).__init__()\n#         self.device = torch.device('cuda')\n#         self.alpha = alpha.to(self.device)\n        self.alpha =alpha\n        self.gamma = gamma\n        self.reduce = reduce\n        self.loss = F.cross_entropy\n#         print(alpha)\n#         print(type(alpha))\n\n    def forward(self, inputs, targets):\n        CE_loss = self.loss(inputs, targets, reduce=False)\n        pt = torch.exp(-CE_loss)\n        F_loss = self.alpha * (1-pt)**self.gamma * CE_loss\n#         CE_loss = self.loss(inputs, targets, reduce=False, weight=self.alpha)\n#         pt = torch.exp(-(self.loss(inputs, targets, reduce=False)))\n# #         pt = torch.exp(-CE_loss)\n#         F_loss = (1-pt)**self.gamma * CE_loss        \n\n        if self.reduce:\n            return torch.mean(F_loss)\n        else:\n            return F_loss    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://gist.github.com/SuperShinyEyes/dcc68a08ff8b615442e3bc6a9b55a354\nclass F1_Loss(nn.Module):\n    '''Calculate F1 score. Can work with gpu tensors\n    \n    The original implmentation is written by Michal Haltuf on Kaggle.\n    \n    Returns\n    -------\n    torch.Tensor\n        `ndim` == 1. epsilon <= val <= 1\n    \n    Reference\n    ---------\n    - https://www.kaggle.com/rejpalcz/best-loss-function-for-f1-score-metric\n    - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score\n    - https://discuss.pytorch.org/t/calculating-precision-recall-and-f1-score-in-case-of-multi-label-classification/28265/6\n    - http://www.ryanzhang.info/python/writing-your-own-loss-function-module-for-pytorch/\n    '''\n    def __init__(self, epsilon=1e-7):\n        super().__init__()\n        self.epsilon = epsilon\n        \n    def forward(self, y_pred, y_true,):\n        assert y_pred.ndim == 2\n        assert y_true.ndim == 1\n        y_true = F.one_hot(y_true, 2).to(torch.float32)\n        y_pred = F.softmax(y_pred, dim=1)\n        \n        tp = (y_true * y_pred).sum(dim=0).to(torch.float32)\n        tn = ((1 - y_true) * (1 - y_pred)).sum(dim=0).to(torch.float32)\n        fp = ((1 - y_true) * y_pred).sum(dim=0).to(torch.float32)\n        fn = (y_true * (1 - y_pred)).sum(dim=0).to(torch.float32)\n\n        precision = tp / (tp + fp + self.epsilon)\n        recall = tp / (tp + fn + self.epsilon)\n\n        f1 = 2* (precision*recall) / (precision + recall + self.epsilon)\n        f1 = f1.clamp(min=self.epsilon, max=1-self.epsilon)\n        return 1 - f1.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel= torchvision.models.resnet50(pretrained=True)\n\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, 2) # target label is 2\ncriterion = nn.CrossEntropyLoss()\n# criterion = FocalLoss(alpha=0.97, gamma=2, reduce=True)\n# criterion = F1_Loss()\n# model_ft = model.cuda()\n\n# save for ensemble\ndefault_model = copy.deepcopy(model.state_dict())\n\n# Observe that all parameters are being optimized\noptimizer = optim.Adam(model.parameters(), lr=0.00008)\n\ndev = \"cuda\"\n# dev = \"cpu\"\ndevice = torch.device(dev)\nmodel.to(device)\ncriterion = criterion.to(device)\n\n# # Decay LR by a factor of 0.1 every 7 epochs\n# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n\nscheduler = lr_scheduler.LambdaLR(\n    optimizer=optimizer, lr_lambda=lambda epoch: 1 / (epoch + 1)\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef model_eval(model, dev='cuda') :\n    device = torch.device(dev)\n#     test_criterion = F1_Loss()\n    test_criterion = nn.CrossEntropyLoss()\n    test_criterion = test_criterion.to(device)\n    model.to(device)\n    model.train(False)\n    data_loader = test_loader\n    running_corrects = 0\n    test_loss = 0\n    \n    # accuracy and loss\n    with torch.no_grad():    \n        for _, pimages, labels in data_loader:\n            pimages = torch.tensor(pimages)\n            labels = torch.tensor(labels)\n            pimages, labels = pimages.to(device), labels.to(device)  \n            outputs = model(pimages)  \n            loss = test_criterion(outputs, labels)\n            _, preds = torch.max(outputs.data, 1)  \n            running_corrects += torch.sum(preds == labels.data)\n            test_loss += (loss*pimages.size()[0])\n        epoch_acc = running_corrects / len(data_loader.dataset)\n#     print('{} loss: {:.4f} Acc: {:.4f}'.format(\n#         'test',test_loss/len(data_loader.dataset), epoch_acc))   \n    \n    return (epoch_acc, test_loss/len(data_loader.dataset))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"기본 테스트"},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_train(train_loader, model) :\n    num_epochs = 10\n    # model.train(True)\n    best_test_acc = 0\n    best_f1_loss = 100\n\n    train_loss = []\n    test_loss = []\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 50)\n        start = time.time()\n        model.train(True)\n\n        running_loss = 0.0\n        running_corrects = 0\n        data_loader = train_loader\n        for i, data in enumerate(data_loader):\n            _, pimages, labels = data\n            pimages = torch.tensor(pimages)\n            labels = torch.tensor(labels)\n            pimages, labels = pimages.to(device), labels.to(device)\n\n            outputs = model(pimages)\n            _, preds = torch.max(outputs.data, 1)\n            loss = criterion(outputs, labels)\n\n            # statistics\n            running_loss += (loss) * pimages.size()[0]\n            running_corrects += torch.sum(preds == labels.data)  \n                \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()                \n\n        epoch_loss = running_loss / len(data_loader.dataset)\n        train_loss.append(float(epoch_loss))\n        epoch_acc = running_corrects / len(data_loader.dataset)\n\n        scheduler.step()\n\n        test_acc, f1_loss = model_eval(model, device)\n        test_loss.append(float(f1_loss))\n        \n        print('train Loss: {:.4f} test Loss: {:.4f} train Acc: {:.4f} test Acc: {:.4f}'.format(\n            epoch_loss, f1_loss, epoch_acc, test_acc))  \n        print('time per epoch :', time.time() - start)        \n        if test_acc > best_test_acc :\n            best_test_acc = test_acc\n#         if f1_loss < best_f1_loss :\n#             best_f1_loss = f1_loss\n            # load best model weights\n            best_model_wts = model.state_dict()\n            print('best model is updated')\n\n        print('-' * 50)\n\n    model.load_state_dict(best_model_wts)\n    test_acc, f1_loss = model_eval(model, device)\n    print('fl_score :', 1-f1_loss)\n    return model, (train_loss, test_loss)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n    \n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model, losses = model_train(train1_loader, model)\n\nfrom matplotlib import pyplot as plt\ntrain_lo, test_lo = losses\nepochs = range(10)\n# list(train_lo)\nplt.plot(epochs, train_lo)\nplt.plot(epochs, test_lo)\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(['Train', 'Test'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_state_dict(default_model)\noptimizer = optim.Adam(model.parameters(), lr=0.00008)\nscheduler = lr_scheduler.LambdaLR(\n    optimizer=optimizer, lr_lambda=lambda epoch: 1 / (epoch + 1)\n)\nmodel, _ = model_train(imbalanced_train_loader, model)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# save model\ntorch.save(model.state_dict(), 'best_model')\n!tar -zcvf best_model.tar.gz best_model\n!ls -al","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"앙상블 테스트"},{"metadata":{"trusted":true},"cell_type":"code","source":"models = []\n\n# training 3 models\nfor data_loader in [train1_loader, train2_loader, train3_loader] :\n    print('*' * 100)\n#     print(data_loader)\n\n    model.load_state_dict(default_model)\n    optimizer = optim.Adam(model.parameters(), lr=0.00008)\n    scheduler = lr_scheduler.LambdaLR(\n        optimizer=optimizer, lr_lambda=lambda epoch: 1 / (epoch + 1)\n    )\n    \n    model, _ = model_train(data_loader, model)\n    models.append(copy.deepcopy(model.state_dict()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# save model\nimport pickle\n\n# save\nwith open('models.pickle', 'wb') as f:\n    pickle.dump(models, f, pickle.HIGHEST_PROTOCOL)\n\n# # load\n# with open('models.pickle', 'rb') as f:\n#     models = pickle.load(f)\n\n!ls -al","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_df.Target[0:20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ensenble test\nimport math\n\npreds = []\nfor m in models :\n    model.load_state_dict(m)\n    model.train(False)\n    data_loader = test_loader\n    running_corrects = 0\n    pred = []\n\n    # accuracy and loss\n    with torch.no_grad():    \n        for _, pimages, labels in data_loader:\n            pimages = torch.tensor(pimages)\n            labels = torch.tensor(labels)\n            pimages, labels = pimages.to(device), labels.to(device) \n            outputs = model(pimages)\n           \n            _, p = torch.max(outputs.data, 1)\n            pred.append(p)\n        preds.append(pred)\n#         print(preds)\n\n# print(len(models))\n# print(preds)\nanswer = []\n# majority voting\nfor a, b, c in zip(preds[0], preds[1], preds[2]) :\n    for i, j, k in zip(a, b, c) :\n        answer.append(round(int(i+j+k)/3))\n# print(answer)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"![](http://)Recall = TP / (TP + FN)  \nPrecision = TP / (TP + FP)  \nAccuracy = (TP + TN) / (TP + FP + FN + TN)  \nF1-Score = 2 * (Recall * Precision) / (Recall + Precision)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(answer)\n# print(test_df.Target[0:20])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# confusion matrix and F1 score of ensenble\nTP, FP, TN, FN = 0,0,0,0\nfor a, p in zip(test_df.Target, answer) :\n    if a == 1 and p == 1 :\n        TP += 1\n    elif a == 1 and p == 0 :\n        FN += 1\n    elif a == 0 and p == 1 :\n        FP += 1\n    elif a == 0 and p == 0 :\n        TN += 1\n\nprint('TP {}, FP {}, TN {}, FN {}'.format(TP, FP, TN, FN))   \nRecall = TP / (TP + FN)\nPrecision = TP / (TP + FP)\nAccuracy = (TP + TN) / (TP + FP + FN + TN)\nF1_Score = 2 * (Recall * Precision) / (Recall + Precision)\nprint('Recall {:.4} precision {:.4}, accuracy {:.4}, F1 score {:.4}'.format(\n    Recall, Precision, Accuracy, F1_Score))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!jupyter nbconvert --to html __notebook_source__.ipynb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls /kaggle/input","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}
